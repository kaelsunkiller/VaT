caption_model: transformer
noamopt: false
reduce_on_plateau: true
#noamopt_warmup: 20000
label_smoothing: 0.0
input_json: ../Self-critical.pytorch/data/f30ktalk.json
input_label_h5: ../Self-critical.pytorch/data/f30ktalk_label.h5
input_att_dir: ../Self-critical.pytorch/data/f30kbu_att.pth
cached_tokens: f30k-train-idxs
seq_per_img: 5
batch_size: 16
learning_rate: 0.00005

# Notice: because I'm to lazy, I reuse the option name for RNNs to set the hyperparameters for transformer:
# N=num_layers
# d_model=input_encoding_size
# d_ff=rnn_size

# will be ignored
num_layers: 6
input_encoding_size: 512
rnn_size: 2048

# Transformer config
N_enc: 4
N_dec: 4
d_model: 512
d_ff: 2048
num_att_heads: 8
dropout: 0.1


learning_rate_decay_start: -1
scheduled_sampling_start: -1 
save_checkpoint_every: 1500
language_eval: 1
val_images_use: -1
max_epochs: 60
train_sample_n: 5

REFORWARD: false

structure_after: 30
structure_loss_weight: 1
structure_loss_type: new_self_critical